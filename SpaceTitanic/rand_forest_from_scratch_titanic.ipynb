{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "#set warning to ignore\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from random import sample,choice\n",
    "from math import sqrt,ceil\n",
    "\n",
    "import logging\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "GINI = \"gini\"\n",
    "ENTROPY = \"entropy\"\n",
    "\n",
    "####Definisco le classi DecisionTree, Question, Leaf, Node\n",
    "class DecisionTree: \n",
    "    \n",
    "    def __init__(self,\n",
    "                 question=None,\n",
    "                 true_branch=None,\n",
    "                 false_branch=None,\n",
    "                 metrics=None, \n",
    "                 max_depth=None,\n",
    "                 leafs=None,\n",
    "                 final_leaf=None,\n",
    "                 final_depth=None):\n",
    "        \n",
    "        self.question = question #è il nodo dell'albero, in cui sono salvate le info sulla feature e relativa soglia di split -> vedi classi Question()\n",
    "        self.true_branch = true_branch\n",
    "        self.false_branch = false_branch\n",
    "        self.max_depth = max_depth #profondita albero\n",
    "        self.leafs = [] #foglie dell'albero (ovvero i nodi finali)\n",
    "        self.final_leaf = final_leaf\n",
    "        self.final_depth = final_depth\n",
    "        \n",
    "        if metrics is None:\n",
    "            self.metrics = GINI  \n",
    "        else:\n",
    "            self.metrics = metrics  \n",
    "   \n",
    "              \n",
    "        \n",
    "    def build_tree(self,train_data,header,count=0):\n",
    "        \n",
    "        \"\"\"Builds the tree.\n",
    "        Try partitioning the dataset on each of the unique attribute,\n",
    "        calculate the information gain,\n",
    "        and return the question that produces the highest gain.\n",
    "        \"\"\"\n",
    "        if count == 0: logging.debug('----NODE 0----')\n",
    "        \n",
    "        #inizio dell'algoritmo, questa funzione a partire dal dataset iniziale trovo la migliore feature e punto di split per ogni iterazione\n",
    "        gain, question = self.find_best_split(train_data, header)\n",
    "            \n",
    "        if isinstance(train_data,pd.DataFrame):\n",
    "            train_data = train_data.values.tolist()\n",
    "        \n",
    "        # Base case: no further info gain\n",
    "        # Since we can ask no further questions,\n",
    "        # we'll return a leaf.\n",
    "        if gain < 0.001:\n",
    "            logging.debug(\"final gain: \",gain)\n",
    "            logging.debug(\"final depth: \",count)\n",
    "            leafs = self.leafs.append(Leaf(train_data))\n",
    "            #logging.debug(leafs)\n",
    "            return DecisionTree(None,\n",
    "                                self.true_branch, \n",
    "                                self.false_branch,\n",
    "                                self.metrics,\n",
    "                                self.max_depth,\n",
    "                                leafs,\n",
    "                                Leaf(train_data),count)\n",
    "        \n",
    "        # Base case: we reached the max depth of the tree\n",
    "        # we'll return a leaf.\n",
    "        if count == self.max_depth:\n",
    "            logging.debug(\"final gain: \",gain)\n",
    "            logging.debug(\"final depth: \",count)\n",
    "            self.leafs.append(Leaf(train_data))\n",
    "            \n",
    "            return DecisionTree(None,\n",
    "                                self.true_branch, \n",
    "                                self.false_branch,\n",
    "                                self.metrics,\n",
    "                                self.max_depth,\n",
    "                                self.leafs,\n",
    "                                Leaf(train_data),count)\n",
    "\n",
    "        \n",
    "        logging.debug(\"best question is ''{}'' with information gain: {}\".format(question,round(gain,2)))\n",
    "        logging.debug(\"depth: \",count)\n",
    "        logging.debug(\"gain: \",gain)\n",
    "        \n",
    "        #divide il dataset in due parti utilizzando la feature e la soglia trovati\n",
    "        true_rows, false_rows = partition(train_data, question)\n",
    "        \n",
    "        # Recursively build the true branch.\n",
    "        logging.debug(\"\\n----TRUE BRANCH----\")\n",
    "        true_branch = self.build_tree(true_rows,header,count+1)\n",
    "        \n",
    "        # Recursively build the false branch.\n",
    "        logging.debug(\"\\n----FALSE BRANCH----\")\n",
    "        false_branch = self.build_tree(false_rows,header,count+1)\n",
    "        \n",
    "        return DecisionTree(question,\n",
    "                            true_branch, \n",
    "                            false_branch,\n",
    "                            self.metrics,\n",
    "                            self.max_depth,\n",
    "                            self.leafs,\n",
    "                            None,count)\n",
    "    \n",
    "    def initialize_split(self,train_data):\n",
    "        \n",
    "        if self.metrics == GINI:\n",
    "            # Calculate the information gain from this split\n",
    "            current_uncertainty = gini(train_data)\n",
    "               \n",
    "        if self.metrics == ENTROPY:\n",
    "            \n",
    "            current_uncertainty = entropy(train_data)\n",
    "        \n",
    "        return current_uncertainty\n",
    "     \n",
    "    def find_best_split(self,train_data,header):\n",
    "        \"\"\"Find the best question to ask by iterating over every feature / value\n",
    "        and calculating the information gain.\"\"\"\n",
    "    \n",
    "        if isinstance(train_data,pd.DataFrame):\n",
    "            train_data = train_data.values.tolist()\n",
    "        \n",
    "        n_features = len(train_data[0]) - 1  # number of columns\n",
    "        \n",
    "        best_gain = 0  # keep track of the best information gain\n",
    "        best_question = None  # keep train of the feature / value that produced it\n",
    "        current_uncertainty = self.initialize_split(train_data)\n",
    "        \n",
    "        for col in range(n_features):  # for each feature\n",
    "            \n",
    "            values = unique_vals(train_data, col)  # unique values in the column\n",
    "            # logging.debug(\"Valori presi in considerazione da find_best_split\")\n",
    "            # logging.debug(\"---------------------------------------------------\")\n",
    "            # logging.debug(\"values features n° {} ''{}'': {}\".format(col+1,header[col],values))\n",
    "            # logging.debug(\"---------------------------------------------------\")\n",
    "            for val in values:  # for each value\n",
    "        \n",
    "                question = Question(header, col, val)\n",
    "                \n",
    "                # try splitting the dataset\n",
    "                true_rows, false_rows = partition(train_data, question)\n",
    "                \n",
    "                # Skip this split if it doesn't divide the dataset.\n",
    "                if len(true_rows) == 1 or len(false_rows) == 1:\n",
    "                    continue\n",
    "                \n",
    "                # Calculate the information gain from this split\n",
    "                gain = info_gain(self.metrics, true_rows, false_rows, current_uncertainty)\n",
    "               \n",
    "                if gain >= best_gain:\n",
    "                    best_gain, best_question = gain, question\n",
    "    \n",
    "        return best_gain, best_question\n",
    "\n",
    "\n",
    "    def classify(self,row):\n",
    "        \"\"\"See the 'rules of recursion' above.\"\"\"\n",
    "        \n",
    "        # Base case: we've reached a leaf\n",
    "        if self.true_branch == None or self.true_branch == None:\n",
    "            logging.debug(\"predictions: {} \".format(self.final_leaf.predictions))\n",
    "            return self.final_leaf.predictions\n",
    "    \n",
    "        logging.debug(\"tree_classifier->classify:\",self.question)\n",
    "       \n",
    "        #logging.debug(\"input value {}\".format(row[node.question.column]))\n",
    "        \n",
    "        #logging.debug(self.question.match(row))\n",
    "        if self.question.match(row):\n",
    "            logging.debug(\"yes\")\n",
    "            return self.true_branch.classify(row)\n",
    "        else:\n",
    "            logging.debug(\"no\")\n",
    "            return self.false_branch.classify(row)\n",
    "    \n",
    "    \n",
    "class Question:\n",
    "    \"\"\"A Question is used to partition a dataset.\n",
    "\n",
    "    This class just records a 'column number' (e.g., 0 for Color) and a\n",
    "    'column value' (e.g., Green). The 'match' method is used to compare\n",
    "    the feature value in an example to the feature value stored in the\n",
    "    question. See the demo below.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,header, column, value):\n",
    "        self.header = header\n",
    "        self.column = column\n",
    "        self.value = value\n",
    "        \n",
    "\n",
    "    def match(self, example):\n",
    "        # Compare the feature value in an example to the\n",
    "        # feature value in this question.\n",
    "        \n",
    "        val = example[self.column]\n",
    "        #logging.debug(\"valore domanda {}\".format(self.value))\n",
    "        #logging.debug(\"::input value {}::\".format(val))\n",
    "        if is_numeric(val):\n",
    "            return val >= self.value\n",
    "        else:\n",
    "            return val == self.value\n",
    "\n",
    "    def __repr__(self):\n",
    "        # This is just a helper method to logging.debug\n",
    "        # the question in a readable format.\n",
    "        condition = \"==\"\n",
    "        if is_numeric(self.value):\n",
    "            condition = \">=\"\n",
    "        return \"Is %s %s %s?\" % (\n",
    "            self.header[self.column], condition, str(self.value))\n",
    " \n",
    "    \n",
    "class Leaf:\n",
    "    \"\"\"A Leaf node classifies data.\n",
    "\n",
    "    This holds a dictionary of class (e.g., \"Apple\") -> number of times\n",
    "    it appears in the rows from the training data that reach this leaf.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, rows):\n",
    "        self.predictions = class_counts(rows)\n",
    "\n",
    "\n",
    "###### UTILITY FUNCTIONS ######       \n",
    "def unique_vals(rows, col):\n",
    "    \"\"\"Find the unique values for a column in a dataset.\"\"\"\n",
    "    return set([row[col] for row in rows])\n",
    "\n",
    "def class_counts(rows):\n",
    "    \"\"\"Counts the number of each type of example in a dataset.\"\"\"\n",
    "    counts = {}  # a dictionary of label -> count.\n",
    "    for row in rows:\n",
    "        # in our dataset format, the label is always the last column\n",
    "        label = row[-1]\n",
    "        if label not in counts:\n",
    "            counts[label] = 0\n",
    "        counts[label] += 1\n",
    "    return counts\n",
    "\n",
    "def print_leaf(counts):\n",
    "    \"\"\"A nicer way to print the predictions at a leaf.\"\"\"\n",
    "    total = sum(counts.values()) * 1.0\n",
    "    probs = {}\n",
    "    for lbl in counts.keys():\n",
    "        probs[lbl] = str(int(counts[lbl] / total * 100)) + \"%\"\n",
    "    return probs\n",
    "\n",
    "def is_numeric(value):\n",
    "    \"\"\"Test if a value is numeric.\"\"\"\n",
    "    return isinstance(value, (int,float))\n",
    "\n",
    "def partition(rows, question):\n",
    "    \"\"\"Partitions a dataset.\n",
    "\n",
    "    For each row in the dataset, check if it matches the question. If\n",
    "    so, add it to 'true rows', otherwise, add it to 'false rows'.\n",
    "    \"\"\"\n",
    "    true_rows, false_rows = [], []\n",
    "    for row in rows:\n",
    "        if question.match(row):\n",
    "            true_rows.append(row)\n",
    "        else:\n",
    "            false_rows.append(row)\n",
    "    return true_rows, false_rows\n",
    "\n",
    "########################## decision tree metrics #############################\n",
    "\n",
    "def gini(rows):\n",
    "    \"\"\"Calculate the Gini Impurity for a list of rows.\n",
    "    p_x = probabilities of find element of \"x\" class \n",
    "    \"\"\"\n",
    "    \n",
    "    classes_count = class_counts(rows)\n",
    "    impurity = 1\n",
    "    for x in classes_count: \n",
    "        p_x = classes_count[x] / float(len(rows))\n",
    "        impurity -= p_x**2\n",
    "    \n",
    "    return impurity\n",
    "\n",
    "\n",
    "def entropy(rows):\n",
    "    \"\"\"\n",
    "    Calculate the entropy of a dataset.\n",
    "    p_x = probabilities of find element of \"x\" class \n",
    "    \"\"\"\n",
    "    classes_count = class_counts(rows)\n",
    "    entropy = 0\n",
    "    for x in classes_count: \n",
    "        p_x = classes_count[x] / float(len(rows))\n",
    "        entropy-=p_x*np.log2(p_x)\n",
    "\n",
    "    return entropy\n",
    "\n",
    "def info_gain(metrics,left, right, current_uncertainty):\n",
    "    \"\"\"Information Gain.\n",
    "\n",
    "    The uncertainty of the starting node, minus the weighted impurity of\n",
    "    two child nodes.\n",
    "    \"\"\"\n",
    "    p = float(len(left)) / (len(left) + len(right))\n",
    "    if metrics == GINI:\n",
    "        # Calculate the information gain from this split\n",
    "        return current_uncertainty - p * gini(left) - (1 - p) * gini(right)\n",
    "               \n",
    "    if metrics == ENTROPY:\n",
    "        return current_uncertainty - p * entropy(left) - (1 - p) * entropy(right)\n",
    "    \n",
    "#given a dictionary return the key with the highest value\n",
    "def max_key(d):\n",
    "    max_key = None\n",
    "    max_value = None\n",
    "    for key,value in d.items():\n",
    "        if max_value is None or value > max_value:\n",
    "            max_key = key\n",
    "            max_value = value\n",
    "    return max_key   \n",
    "       \n",
    "#calculate accuracy from pandas series\n",
    "def get_accuracy_score(y_true,y_pred):\n",
    "    return np.sum(y_true == y_pred)/len(y_true)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_var_pos(header,var_tree):\n",
    "    \n",
    "    input_variables = []\n",
    "    for var in var_tree:\n",
    "        for idx,head in enumerate(header):\n",
    "            if var == head:\n",
    "                input_variables.append(idx)\n",
    "                \n",
    "    return input_variables\n",
    "\n",
    "def sub_sample_and_features(df,labels,n_selected_features,sample_ratio = 0.5):\n",
    "    \n",
    "    n_features = df.shape[1]-1\n",
    "    n_row = df.shape[0]\n",
    "\n",
    "    #estrae un sample degli indici delle righe di dimensione pari a n_row*sample_ratio\n",
    "    sampled_row = sample(range(0,n_row), round(n_row*float(sample_ratio)))\n",
    "    \n",
    "    \n",
    "    if n_selected_features == \"best\":\n",
    "        #estrae un sample delle features di dimensione pari a sqrt(n_features)\n",
    "        selected_features = sample(range(0,n_features), ceil(sqrt(n_features)))\n",
    "    elif n_selected_features == \"all\":\n",
    "        #estrae un sample delle features di dimensione pari a n_features\n",
    "        selected_features = sample(range(0,n_features), n_features)\n",
    "    else:\n",
    "        #estrae un sample delle features di dimensione pari a n_selected_features\n",
    "        selected_features = sample(range(0,n_features), n_selected_features)\n",
    "    \n",
    "    df_sel = df.iloc[sampled_row,selected_features]\n",
    "    \n",
    "    bootstrap_sample = df_sel.join(labels)#.reset_index(drop=True)\n",
    "    \n",
    "    out_of_bag_sample = df.drop(df.index[sampled_row])[bootstrap_sample.columns.tolist()]#.reset_index(drop=True)\n",
    "    \n",
    "    return bootstrap_sample,out_of_bag_sample\n",
    "\n",
    "class RandomForest():\n",
    "    \n",
    "    '''Random Forest:\n",
    "       - decision_tree_type: tipologia di albero da utilizzare (con gini o con entropia)\n",
    "       - n_trees: numero di alberi da utilizzare nella foresta\n",
    "       - trained_trees: in questa variabile vengono salvati tutti gli alberi della foresta (già addestrati)\n",
    "    '''    \n",
    "    \n",
    "    def __init__(self,decision_tree_type,n_trees,trained_trees=None#,out_of_bag_predictions=[]\n",
    "                 ):\n",
    "        self.decision_tree_type = decision_tree_type\n",
    "        self.n_trees = n_trees\n",
    "        self.trained_trees = trained_trees\n",
    "        #self.out_of_bag_predictions = out_of_bag_predictions\n",
    "\n",
    "    def build_forest(self,train_data_df,sample_ratio,n_selected_features):\n",
    "        \n",
    "        random_forest = []\n",
    "        labels = train_data_df.iloc[:,-1]\n",
    "        \n",
    "        for i in range(0,self.n_trees):\n",
    "            print(\"::::::::::::::TREE N° {}::::::::::::::\".format(i))\n",
    "            \n",
    "            #effettuo il sub sampling e la selezione delle features\n",
    "            #se n_selected_features = \"best\" allora seleziona la radice quadrata del numero di features\n",
    "            bootstrap_sample,out_of_bag_sample = sub_sample_and_features(train_data_df,labels,n_selected_features,sample_ratio)\n",
    "            \n",
    "            header = bootstrap_sample.columns.values.tolist() #qui salvo le variabili utilizzate dall'albero\n",
    "            \n",
    "            trained_tree = self.decision_tree_type.build_tree(bootstrap_sample,header[:-1]) #addestro l'albero i-esimo con il sub sample del training set\n",
    "            \n",
    "            print(\"Variabili utilizzate: {}\".format(header[:-1]))\n",
    "            print(\"Numero di record utilizzati: {}\".format(bootstrap_sample.shape[0]))\n",
    "            \n",
    "            '''calcolo degli out of bag predictions'''\n",
    "            out_of_bag_sample['pred'] = out_of_bag_sample.loc[:,out_of_bag_sample.columns != 'Transported'].apply(lambda x: max_key(trained_tree.classify(x)),axis=1)\n",
    "            \n",
    "            out_of_bag_sample = out_of_bag_sample.drop(out_of_bag_sample.columns.difference(['pred','Transported','PassengerId']), 1)\n",
    "            \n",
    "            self.out_of_bag_predictions = self.out_of_bag_predictions.append(out_of_bag_sample)\n",
    "            \n",
    "            #join all the dataframe in the list out_of_bag_predictions on the column 'PassengerId'\n",
    "            final_df = reduce(lambda left,right: pd.merge(left,right,on='PassengerId'), self.out_of_bag_predictions)\n",
    "            \n",
    "            #for each passengerId, get the most voted prediction\n",
    "            #final_df_pred = final_df.groupby('PassengerId').agg(lambda x:x.value_counts().index[0])\n",
    "            \n",
    "            #print(\"Accuracy sull'out of bag sample: {}\".format(score))\n",
    "            \n",
    "            #----------------------\n",
    "                \n",
    "            #salva l'albero addestrato nella property trained_trees e relative variabili utilizzate nell'oggetto RandomForest\n",
    "            random_forest.append([header,trained_tree])\n",
    "        \n",
    "        return RandomForest(self.decision_tree_type, self.n_trees, random_forest)\n",
    "    \n",
    "    \n",
    "    def classify_forest(self,data_variables,data):\n",
    "        \n",
    "        tree_predictions = Counter()\n",
    "        \n",
    "        for j in self.trained_trees:       \n",
    "            tree = j[1] #seleziono l'albero j-esimo della foresta\n",
    "            selected_var = data[get_input_var_pos(data_variables,j[0])] #seleziono le variabili utilizzate dall'albero j-esimo\n",
    "            pred = tree.classify(selected_var) #classifico la riga data con l'albero j-esimo\n",
    "            for key,value in pred.items():\n",
    "                tree_predictions[key] += value\n",
    "        \n",
    "        final_prediction = tree_predictions.most_common()[0]\n",
    "        \n",
    "        #print(\"Classificato come {} con {} voti\".format(final_prediction[0],final_prediction[1]))      \n",
    "        return final_prediction[0]\n",
    "        \n",
    "        \n",
    "    def get_model_accuracy(self,data_variables,validate_data):\n",
    "        #TO-DO\n",
    "        labels = validate_data.iloc[:,-1].values\n",
    "        \n",
    "        predictions = []\n",
    "        for i,row in enumerate(validate_data.values):            \n",
    "            pred = self.classify_forest(data_variables,row)\n",
    "            predictions.append(pred)\n",
    "            #print(\"Y_pred= {}; Y= {}\".format(pred,labels[i]))\n",
    "        \n",
    "        predictions = np.array(predictions)\n",
    "        print()\n",
    "        if len(labels) == len(predictions):\n",
    "                \n",
    "            if is_numeric(predictions) and is_numeric(labels[0]):\n",
    "                \n",
    "                E_SS = np.sum((predictions - labels.mean()) ** 2)\n",
    "                T_SS = np.sum((labels - labels.mean())** 2)\n",
    "                print(\"Accuratezza modello del {}\".format(E_SS/T_SS))\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                acc = [1 if x == y else 0  for x, y in zip(labels, predictions)]\n",
    "                acc_tot = sum(acc)/len(labels) * 100\n",
    "                print(\"Accuratezza modello del {}\".format(acc_tot))\n",
    "                \n",
    "        return predictions   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bootstrap_sample,out_of_bag_sample=sub_sample_and_features(space_titanic_df, space_titanic_df.iloc[:,-1],2,0.8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dei dataset e cleaning dei dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_titanic_df = pd.read_csv('SpaceTitanic/train.csv',index_col=0)\n",
    "space_titanic_df_test = pd.read_csv('SpaceTitanic/test.csv',index_col=0)\n",
    "\n",
    "#remove the columns cabin and name from the dataset\n",
    "space_titanic_df = space_titanic_df.drop(['Cabin','Name'],axis=1)\n",
    "space_titanic_df_test = space_titanic_df_test.drop(['Cabin','Name'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in space_titanic_df.columns[:-1]:\n",
    "    if space_titanic_df[col].dtype == 'float64' or space_titanic_df[col].dtype == 'int64':\n",
    "        space_titanic_df[col] = space_titanic_df[col].fillna(space_titanic_df[col].median())\n",
    "    elif space_titanic_df[col].dtype == 'object' and type(space_titanic_df[col][0])==str:\n",
    "        space_titanic_df[col] = space_titanic_df[col].fillna('unknown')\n",
    "    elif space_titanic_df[col].dtype == 'object' and type(space_titanic_df[col][0])==bool:\n",
    "        space_titanic_df[col] = space_titanic_df['CryoSleep'].fillna(choice([True,False]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>missing_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HomePlanet</th>\n",
       "      <td>object</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CryoSleep</th>\n",
       "      <td>bool</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Destination</th>\n",
       "      <td>object</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>float64</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VIP</th>\n",
       "      <td>bool</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RoomService</th>\n",
       "      <td>float64</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FoodCourt</th>\n",
       "      <td>float64</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ShoppingMall</th>\n",
       "      <td>float64</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spa</th>\n",
       "      <td>float64</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VRDeck</th>\n",
       "      <td>float64</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Transported</th>\n",
       "      <td>bool</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 type  missing_values\n",
       "HomePlanet     object             0.0\n",
       "CryoSleep        bool             0.0\n",
       "Destination    object             0.0\n",
       "Age           float64             0.0\n",
       "VIP              bool             0.0\n",
       "RoomService   float64             0.0\n",
       "FoodCourt     float64             0.0\n",
       "ShoppingMall  float64             0.0\n",
       "Spa           float64             0.0\n",
       "VRDeck        float64             0.0\n",
       "Transported      bool             0.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#concatenate two series in a single dataframe\n",
    "series1 = space_titanic_df.dtypes\n",
    "series2 = round((space_titanic_df.isna().sum()/space_titanic_df.shape[0])*100,2)\n",
    "\n",
    "pd.DataFrame({'type':series1,'missing_values':series2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each numeric column with missing values, fill the missing values with the median of the column\n",
    "#for each string column with missing values, fill the missing values with an unknown category\n",
    "\n",
    "for col in space_titanic_df.columns[:-1]:\n",
    "    if space_titanic_df[col].dtype == 'float64' or space_titanic_df[col].dtype == 'int64':\n",
    "        space_titanic_df[col] = space_titanic_df[col].fillna(space_titanic_df[col].median())\n",
    "    if space_titanic_df[col].dtype == 'object':\n",
    "        space_titanic_df[col] = space_titanic_df[col].fillna('unknown')\n",
    "        \n",
    "for col in space_titanic_df_test.columns[:-1]:\n",
    "    if space_titanic_df_test[col].dtype == 'float64' or space_titanic_df_test[col].dtype == 'int64':\n",
    "        space_titanic_df_test[col] = space_titanic_df_test[col].fillna(space_titanic_df_test[col].median())\n",
    "    if space_titanic_df_test[col].dtype == 'object':\n",
    "        space_titanic_df_test[col] = space_titanic_df_test[col].fillna('unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#move the column transported at the end of the dataset\n",
    "col = space_titanic_df.pop('Transported')\n",
    "space_titanic_df['Transported'] = col\n",
    "\n",
    "#split the datwaset in train and validation\n",
    "space_titanic_df_train, space_titanic_df_val = train_test_split(space_titanic_df, test_size=0.1, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting dei modelli e prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''CREATE SINGLE TREE'''\n",
    "d_t = DecisionTree(metrics = 'entropy') #max_depth = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CREATE RANDOM FOREST WITH TREES d_t'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''CREATE RANDOM FOREST WITH TREES d_t'''\n",
    "#r_f = RandomForest(decision_tree_type=d_t, n_trees=2)\n",
    "#r_f = r_f.build_forest(space_titanic_df_train, \n",
    "#                       sample_ratio =.9, \n",
    "#                       n_selected_features=6 #\"best\"\n",
    "#                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "::::::::::::::TREE N° 0::::::::::::::\n",
      "Variabili utilizzate: ['ShoppingMall', 'RoomService', 'Destination', 'FoodCourt']\n",
      "Numero di record utilizzati: 7041\n",
      "\n",
      "Accuratezza modello del 70.80459770114943\n",
      "::::::::::::::TREE N° 0::::::::::::::\n",
      "Variabili utilizzate: ['RoomService', 'Age', 'HomePlanet', 'Spa']\n",
      "Numero di record utilizzati: 7041\n",
      "::::::::::::::TREE N° 1::::::::::::::\n",
      "Variabili utilizzate: ['VIP', 'Age', 'Destination', 'Spa']\n",
      "Numero di record utilizzati: 7041\n",
      "\n",
      "Accuratezza modello del 72.06896551724138\n",
      "::::::::::::::TREE N° 0::::::::::::::\n",
      "Variabili utilizzate: ['HomePlanet', 'Spa', 'ShoppingMall', 'FoodCourt']\n",
      "Numero di record utilizzati: 7041\n",
      "::::::::::::::TREE N° 1::::::::::::::\n",
      "Variabili utilizzate: ['RoomService', 'ShoppingMall', 'FoodCourt', 'Age']\n",
      "Numero di record utilizzati: 7041\n",
      "::::::::::::::TREE N° 2::::::::::::::\n",
      "Variabili utilizzate: ['VIP', 'Age', 'Spa', 'ShoppingMall']\n",
      "Numero di record utilizzati: 7041\n",
      "\n",
      "Accuratezza modello del 71.60919540229885\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#FIND THE BEST NUMBER OF TREES BETWEEN 30,40,50,60,70,80,90,100 WITH N_SELECTED_FEATURES between 'best',6,8, create a plot e return the model with highest accuracy:\n",
    "\n",
    "def find_best_n_trees(space_titanic_df_train, space_titanic_df_val, n_trees_list, sample_ratio, n_selected_features):\n",
    "    #TO-DO\n",
    "    accuracies = []\n",
    "    models = []\n",
    "    \n",
    "    for n_trees in n_trees_list:\n",
    "        r_f = RandomForest(decision_tree_type=d_t, n_trees=n_trees)\n",
    "        r_f = r_f.build_forest(space_titanic_df_train, \n",
    "                                sample_ratio =sample_ratio, \n",
    "                                n_selected_features=n_selected_features)\n",
    "        predictions = r_f.get_model_accuracy(space_titanic_df_val.columns[:-1],space_titanic_df_val)\n",
    "        accuracies.append(accuracy_score(space_titanic_df_val.iloc[:,-1].values,predictions))\n",
    "        models.append(r_f)\n",
    "        \n",
    "    plt.plot(n_trees_list,accuracies)\n",
    "    plt.xlabel('n_trees')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.show()\n",
    "    \n",
    "    return models[accuracies.index(max(accuracies))]\n",
    "\n",
    "best_model = find_best_n_trees(space_titanic_df_train, space_titanic_df_val, [1,2,3], .9, 'best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.RandomForest at 0x23e1f23ec40>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m'''GET MODEL ACCURACY ON VALIDATION DATA'''\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m predictions_validation \u001b[39m=\u001b[39m r_f\u001b[39m.\u001b[39;49mget_model_accuracy(space_titanic_df_val\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mvalues\u001b[39m.\u001b[39;49mtolist(), space_titanic_df_val)  \n",
      "Cell \u001b[1;32mIn[39], line 118\u001b[0m, in \u001b[0;36mRandomForest.get_model_accuracy\u001b[1;34m(self, data_variables, validate_data)\u001b[0m\n\u001b[0;32m    116\u001b[0m predictions \u001b[39m=\u001b[39m []\n\u001b[0;32m    117\u001b[0m \u001b[39mfor\u001b[39;00m i,row \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(validate_data\u001b[39m.\u001b[39mvalues):            \n\u001b[1;32m--> 118\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclassify_forest(data_variables,row)\n\u001b[0;32m    119\u001b[0m     predictions\u001b[39m.\u001b[39mappend(pred)\n\u001b[0;32m    120\u001b[0m     \u001b[39m#print(\"Y_pred= {}; Y= {}\".format(pred,labels[i]))\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[39], line 99\u001b[0m, in \u001b[0;36mRandomForest.classify_forest\u001b[1;34m(self, data_variables, data)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mclassify_forest\u001b[39m(\u001b[39mself\u001b[39m,data_variables,data):\n\u001b[0;32m     97\u001b[0m     tree_predictions \u001b[39m=\u001b[39m Counter()\n\u001b[1;32m---> 99\u001b[0m     \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrained_trees:       \n\u001b[0;32m    100\u001b[0m         tree \u001b[39m=\u001b[39m j[\u001b[39m1\u001b[39m] \u001b[39m#seleziono l'albero j-esimo della foresta\u001b[39;00m\n\u001b[0;32m    101\u001b[0m         selected_var \u001b[39m=\u001b[39m data[get_input_var_pos(data_variables,j[\u001b[39m0\u001b[39m])] \u001b[39m#seleziono le variabili utilizzate dall'albero j-esimo\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "'''GET MODEL ACCURACY ON VALIDATION DATA'''\n",
    "predictions_validation = r_f.get_model_accuracy(space_titanic_df_val.columns.values.tolist(), space_titanic_df_val)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = space_titanic_df_val.iloc[:,-1].values\n",
    "acc = [1 if x == y else 0  for x, y in zip(labels, predictions_validation)]\n",
    "acc_tot = sum(acc)/len(labels) * 100\n",
    "print(\"Accuratezza modello del {}\".format(acc_tot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for i,row in enumerate(space_titanic_df_val.values):            \n",
    "    pred = r_f.classify_forest(space_titanic_df_val.columns.values.tolist(),row)\n",
    "    predictions.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_titanic_df_val['pred'] = space_titanic_df_val.apply(lambda x: best_model.classify_forest(space_titanic_df_val.columns.values.tolist(),x),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Transported</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0337_02</th>\n",
       "      <td>Mars</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>19.0</td>\n",
       "      <td>False</td>\n",
       "      <td>417.0</td>\n",
       "      <td>349.0</td>\n",
       "      <td>634.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1057.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2891_01</th>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>18.0</td>\n",
       "      <td>False</td>\n",
       "      <td>4.0</td>\n",
       "      <td>904.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8998_01</th>\n",
       "      <td>Earth</td>\n",
       "      <td>True</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>41.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1771_01</th>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>35.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>338.0</td>\n",
       "      <td>436.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9034_02</th>\n",
       "      <td>Europa</td>\n",
       "      <td>True</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>43.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6671_03</th>\n",
       "      <td>Mars</td>\n",
       "      <td>False</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>14.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1880.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5367_01</th>\n",
       "      <td>Europa</td>\n",
       "      <td>True</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6167_01</th>\n",
       "      <td>Earth</td>\n",
       "      <td>True</td>\n",
       "      <td>PSO J318.5-22</td>\n",
       "      <td>42.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5034_01</th>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4160.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9161_01</th>\n",
       "      <td>Earth</td>\n",
       "      <td>True</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>38.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>870 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            HomePlanet  CryoSleep    Destination   Age    VIP  RoomService  \\\n",
       "PassengerId                                                                  \n",
       "0337_02           Mars      False    TRAPPIST-1e  19.0  False        417.0   \n",
       "2891_01          Earth      False    TRAPPIST-1e  18.0  False          4.0   \n",
       "8998_01          Earth       True    TRAPPIST-1e  41.0   True          0.0   \n",
       "1771_01          Earth      False    TRAPPIST-1e  35.0  False          0.0   \n",
       "9034_02         Europa       True    TRAPPIST-1e  43.0   True          0.0   \n",
       "...                ...        ...            ...   ...    ...          ...   \n",
       "6671_03           Mars      False    55 Cancri e  14.0  False       1880.0   \n",
       "5367_01         Europa       True    TRAPPIST-1e   4.0   True          0.0   \n",
       "6167_01          Earth       True  PSO J318.5-22  42.0   True          0.0   \n",
       "5034_01          Earth      False    TRAPPIST-1e  36.0  False          0.0   \n",
       "9161_01          Earth       True    55 Cancri e  38.0   True          0.0   \n",
       "\n",
       "             FoodCourt  ShoppingMall  Spa  VRDeck  Transported   pred  \n",
       "PassengerId                                                            \n",
       "0337_02          349.0         634.0  3.0  1057.0         True  False  \n",
       "2891_01          904.0           0.0  0.0     1.0        False  False  \n",
       "8998_01            0.0           0.0  0.0     0.0        False   True  \n",
       "1771_01          338.0         436.0  0.0     0.0         True  False  \n",
       "9034_02            0.0           0.0  0.0     0.0         True   True  \n",
       "...                ...           ...  ...     ...          ...    ...  \n",
       "6671_03            0.0          15.0  0.0     0.0        False  False  \n",
       "5367_01            0.0           0.0  0.0     0.0         True   True  \n",
       "6167_01            0.0           0.0  0.0     0.0         True   True  \n",
       "5034_01           52.0           8.0  0.0  4160.0        False  False  \n",
       "9161_01            0.0           0.0  0.0     0.0        False   True  \n",
       "\n",
       "[870 rows x 12 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "space_titanic_df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#space_titanic_df_test['Transported'] = \n",
    "space_titanic_df_test.apply(lambda x: r_f.classify_forest(space_titanic_df_test.columns.values.tolist(),x),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = space_titanic_df_test.reset_index()[['PassengerId','Transported']]\n",
    "submission = submission.set_index('PassengerId')\n",
    "submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
