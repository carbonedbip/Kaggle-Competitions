{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c0375d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importo le librerie necessarie\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#definisco l'algoritmo come una classe\n",
    "class Perceptron(object):\n",
    "    \n",
    "    #inizializzatore\n",
    "    def __init__(self, eta=0.01, n_iter=50, random_state=1):\n",
    "        self.eta = eta\n",
    "        self.n_iter = n_iter\n",
    "        self.random_state = random_state\n",
    "    \n",
    "    #funzione per il fitting dei dati di training\n",
    "    def fit(self, X, y):\n",
    "        rgen = np.random.RandomState(self.random_state)\n",
    "        self.w_ = rgen.normal (loc=0.0, scale=0.01, size=1+X.shape[1])\n",
    "        \n",
    "        self.errors_ = []\n",
    "        \n",
    "        for _ in range(self.n_iter):\n",
    "            errors = 0\n",
    "            for xi, target in zip(X, y):\n",
    "                update = self.eta * (target - self.predict(xi))\n",
    "                self.w_[1:] += update * xi\n",
    "                self.w_[0] += update\n",
    "                errors += int(update != 0.0)\n",
    "            self.errors_.append(errors)\n",
    "        return self\n",
    "    \n",
    "    #funzione per calcolare il net input\n",
    "    def net_input(self, X):\n",
    "        return np.dot(X, self.w_[1:]) + self.w_[0]\n",
    "    \n",
    "    #funzione per predire i valori delle y\n",
    "    def predict(self, X):\n",
    "        return np.where(self.net_input(X) >= 0.0, 1, -1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe2e850",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import del dataset\n",
    "dataset = pd.read_excel(r\"C:\\Users\\fspadafora\\OneDrive - BUSINESS INTEGRATION PARTNERS SPA\\Desktop\\KAGGLE\\spaceship-titanic\\train.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9653a5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trasformo le due variabili binarie in true/false \n",
    "dataset['CryoSleep'] = np.where(dataset['CryoSleep'] > 0, 'True', 'False')\n",
    "dataset['VIP'] = np.where(dataset['VIP'] > 0, 'True', 'False')\n",
    "\n",
    "#trasformo la variabile target da true/false a 1/-1\n",
    "dataset['Transported'] = np.where(dataset['Transported'] == True, 1, -1)\n",
    "\n",
    "#rimuovo le variabili non numeriche dal dataset\n",
    "df = dataset.drop(['PassengerId', 'HomePlanet', 'CryoSleep', 'Cabin', 'Destination', 'VIP', 'Name'], axis=1)\n",
    "\n",
    "#rimuovo missing values\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e095ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardizzo le variabili\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "df[['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']] = scaler.fit_transform(df[['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1211ca3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ = df.iloc[0:, 6].values\n",
    "y = y_.reshape(len(y_), 1)\n",
    "#X = df.iloc[0:, [0,1]].values\n",
    "X = df.iloc[0:, 0:5].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a13e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparo gli array per il grafico nel caso di sole 2 features\n",
    "lX1 = []\n",
    "lX2 = []\n",
    "counter = 0\n",
    "for xi, target in zip(X, y):\n",
    "    if target == 1:\n",
    "        lX1.append(list(X[counter, (0,1)]))\n",
    "    else:\n",
    "        lX2.append(list(X[counter, (0,1)]))\n",
    "    counter += 1\n",
    "    \n",
    "X1 = np.asarray(lX1)\n",
    "X2 = np.asarray(lX2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6eaa52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#faccio il grafico delle X nel caso di 2 sole features\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(X1[0:100,0], X1[0:100,1], color='red', marker='o', label='transposed = 1')\n",
    "plt.scatter(X2[0:100,0], X2[0:100,1], color='blue', marker='x',label='transposed = -1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30618f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inizializzo un'istanza della classe Perceptron (ovvero dell'algoritmo)\n",
    "p = Perceptron(0.01, 100, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa338e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lancio la funzione per il training del modello\n",
    "p.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b258d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vedo i valori dei parametri\n",
    "p.w_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e25217",
   "metadata": {},
   "outputs": [],
   "source": [
    "#valuto lo score\n",
    "score = 1 - (p.errors_[(len(p.errors_) - 1)] / df.shape[0])\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4af728d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the misclassification error for each epoch to check whether the algorithm converged and found a decision boundary\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(1, len(p.errors_) + 1),\n",
    "p.errors_, marker='o')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Number of updates')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a7484a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#implementazione del Perceptron di sklearn come termine di paragone\n",
    "from sklearn.linear_model import Perceptron\n",
    "clf = Perceptron(tol=1e-3, random_state=0, eta0 = 0.01)\n",
    "clf.fit(X, y)\n",
    "Perceptron()\n",
    "clf.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7af6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ulteriore implementazione del Perceptron leggermente piÃ¹ sofisticata con forward e back propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03617d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#definisco le funzioni\n",
    "\n",
    "def activation_function(prediction):\n",
    "    \"\"\"\n",
    "    Receives the output of the perceptron's function as parameter, and applies the\n",
    "    activation function on it.\n",
    "    For the purpose of this project, the activation function maps the negative outputs\n",
    "    to 0 and the positive ones to 1\n",
    "    \"\"\"\n",
    "    if prediction >= 0:\n",
    "        return 1\n",
    "    return -1\n",
    "\n",
    "\n",
    "def predict(x, weights, bias):\n",
    "    \"\"\"\n",
    "    Predicts the class of a given data point (x), by applying the Perceptron's \n",
    "    function, and the activation function lastly.\n",
    "    As both weights and x are vectors, the dot product is used.\n",
    "    \"\"\"\n",
    "    prediction = np.dot(weights, x) + bias\n",
    "    prediction = activation_function(prediction)\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "\n",
    "def forward_propagation(x, y, weights, bias): \n",
    "    \"\"\"\n",
    "    x: training data as a vector (nparray), where each value corresponds\n",
    "        to a feature's value\n",
    "    y: label (-1 or 1)\n",
    "    weights: weights of the perceptron\n",
    "    bias: bias\n",
    "    \"\"\"\n",
    "    y_pred = predict(x, weights, bias)\n",
    "    loss = (y_pred - y)**2   \n",
    "    d_loss = 2*(y_pred - y)\n",
    "    \n",
    "    return y_pred, loss, d_loss\n",
    "\n",
    "\n",
    "def backpropagation(x, d_loss):\n",
    "    \"\"\"\n",
    "    Performs the Backpropagation step on a given data point.\n",
    "    receives as input the data point, the Perceptron's weights and the partial derivative of the loss\n",
    "    over the predicted y.\n",
    "    The received derivative is used to calculate the partial derivative of the loss over the weight of each feature.\n",
    "    A list with the partial derivatives of the loss over each weight is returned.\n",
    "    \"\"\"\n",
    "    partial_derivates = list()\n",
    "    for feature_value in x:\n",
    "        partial_derivates.append(d_loss*feature_value)\n",
    "        \n",
    "    return partial_derivates \n",
    "\n",
    "\n",
    "def optimize_perceptron(x, y, learning_rate):\n",
    "    \"\"\"\n",
    "    Optimizes the Perceptron's weights by looping over the same steps for as many epochs as the user wants.\n",
    "    Steps:\n",
    "    1. Forward propagate data point\n",
    "    2. Backpropagate\n",
    "    3. Update weights\n",
    "    4. Check stop conditions while looping\n",
    "    \n",
    "    It is worth nothing that a history of the Perceptron's losses over each epoch is kept,\n",
    "    which will be used\n",
    "    \"\"\"\n",
    "    weights = np.random.rand(x.shape[1])\n",
    "    bias = np.random.rand()\n",
    "    \n",
    "    epoch = 0\n",
    "    error = 999\n",
    "    \n",
    "    errors = list()\n",
    "    epochs = list()\n",
    "    \n",
    "    # Loop until stop conditions are met\n",
    "    while epoch <= 1000 and error > 9e-4:\n",
    "        \n",
    "        loss_ = 0\n",
    "        # Loop over every data point\n",
    "        for i in range(x.shape[0]):\n",
    "            \n",
    "            # Forward Propagation on each data point\n",
    "            y_pred, loss, d_loss = forward_propagation(x[i], y[i], weights, bias)\n",
    "\n",
    "            # Backpropagation\n",
    "            partial_derivates = backpropagation(x[i], d_loss)\n",
    "            \n",
    "            # Learn by updating the weights of the perceptron\n",
    "            weights = weights - (learning_rate * np.array(partial_derivates))\n",
    "\n",
    "        # Evaluate the results\n",
    "        for index, feature_value_test in enumerate(x):\n",
    "            y_pred, loss, d_loss = forward_propagation(feature_value_test, y[index], weights, bias)\n",
    "            loss_ += loss\n",
    "\n",
    "        errors.append(loss_/len(x))\n",
    "        epochs.append(epoch)\n",
    "        error = errors[-1]\n",
    "        epoch += 1\n",
    "\n",
    "        print('Epoch {}. loss: {}'.format(epoch, errors[-1]))\n",
    "\n",
    "    \n",
    "    return weights, bias, errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d32567",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = optimize_perceptron(X, y, 0.01)\n",
    "pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dfe045",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
